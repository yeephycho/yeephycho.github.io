<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>A Note to Techniques in Convolutional Neural Networks and Their Influences III (paper summary) | yeephycho</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Since we have already got some bases on how CNN works, so this post I prefer to focus more on the ideologies that make these architectures unique and the general technics that can improve the performa">
<meta property="og:type" content="article">
<meta property="og:title" content="A Note to Techniques in Convolutional Neural Networks and Their Influences III (paper summary)">
<meta property="og:url" content="http://yeephycho.github.io/2016/08/31/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-III/index.html">
<meta property="og:site_name" content="yeephycho">
<meta property="og:description" content="Since we have already got some bases on how CNN works, so this post I prefer to focus more on the ideologies that make these architectures unique and the general technics that can improve the performa">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/deconv.JPG">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/mlpconv.jpg">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/nin.jpg">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/VGG.JPG">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/Inception_v4.jpg">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/Inception_ResNet_v2.jpg">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/license.jpg">
<meta property="og:image" content="http://yeephycho.github.io/blog_img/APACHE.jpg">
<meta property="og:updated_time" content="2016-10-31T02:12:26.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Note to Techniques in Convolutional Neural Networks and Their Influences III (paper summary)">
<meta name="twitter:description" content="Since we have already got some bases on how CNN works, so this post I prefer to focus more on the ideologies that make these architectures unique and the general technics that can improve the performa">
<meta name="twitter:image" content="http://yeephycho.github.io/blog_img/deconv.JPG">
  
    <link rel="alternative" href="/atom.xml" title="yeephycho" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://yeephycho.github.io/blog_img/zombie2.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">yeephycho</a></h1>
		</hgroup>

		
		<p class="header-subtitle">Possibly, yeephycho is a phycho.</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						
						<li>About</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/yeephycho.github.io">Home Page</a></li>
				        
							<li><a href="/archives">All article</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/yeephycho" title="github">github</a>
					        
								<a class="linkedin" target="_blank" href="https://www.linkedin.com/in/%E4%BB%A5%E7%92%87-%E8%83%A1-82ab00102" title="linkedin">linkedin</a>
					        
								<a class="facebook" target="_blank" href="https://www.facebook.com/profile.php?id=100004383827370" title="facebook">facebook</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/AlexNet/" style="font-size: 13.33px;">AlexNet</a> <a href="/tags/Android/" style="font-size: 10px;">Android</a> <a href="/tags/Android-Native/" style="font-size: 10px;">Android Native</a> <a href="/tags/Author/" style="font-size: 10px;">Author</a> <a href="/tags/BN-Inception/" style="font-size: 10px;">BN-Inception</a> <a href="/tags/Batch-Normalization/" style="font-size: 10px;">Batch Normalization</a> <a href="/tags/Blog/" style="font-size: 10px;">Blog</a> <a href="/tags/C-C/" style="font-size: 13.33px;">C/C++</a> <a href="/tags/CUDA/" style="font-size: 10px;">CUDA</a> <a href="/tags/Convolutional-Neural-Network/" style="font-size: 20px;">Convolutional Neural Network</a> <a href="/tags/GoogLeNet/" style="font-size: 13.33px;">GoogLeNet</a> <a href="/tags/Histogram-equalization/" style="font-size: 10px;">Histogram equalization</a> <a href="/tags/Inception-module/" style="font-size: 10px;">Inception module</a> <a href="/tags/Inception-v3/" style="font-size: 10px;">Inception-v3</a> <a href="/tags/Inception-v4/" style="font-size: 10px;">Inception-v4</a> <a href="/tags/Input-Data/" style="font-size: 10px;">Input Data</a> <a href="/tags/Julia-set/" style="font-size: 10px;">Julia set</a> <a href="/tags/LeNet-5/" style="font-size: 13.33px;">LeNet-5</a> <a href="/tags/License/" style="font-size: 10px;">License</a> <a href="/tags/Local-Contrast-Normalization/" style="font-size: 10px;">Local Contrast Normalization</a> <a href="/tags/Local-Response-Normalization/" style="font-size: 10px;">Local Response Normalization</a> <a href="/tags/MLPCONV/" style="font-size: 10px;">MLPCONV</a> <a href="/tags/Machine-Learning/" style="font-size: 16.67px;">Machine Learning</a> <a href="/tags/NDK/" style="font-size: 10px;">NDK</a> <a href="/tags/Neon/" style="font-size: 10px;">Neon</a> <a href="/tags/Neural-Style/" style="font-size: 10px;">Neural Style</a> <a href="/tags/OpenBLAS/" style="font-size: 10px;">OpenBLAS</a> <a href="/tags/OpenCL/" style="font-size: 10px;">OpenCL</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/OpenMP/" style="font-size: 10px;">OpenMP</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a> <a href="/tags/Shared-Library/" style="font-size: 10px;">Shared Library</a> <a href="/tags/Tensorflow/" style="font-size: 10px;">Tensorflow</a> <a href="/tags/Tensorflow-Torch7/" style="font-size: 10px;">Tensorflow/Torch7</a> <a href="/tags/Torch-Android/" style="font-size: 10px;">Torch-Android</a> <a href="/tags/Tutorial/" style="font-size: 10px;">Tutorial</a> <a href="/tags/VGGNet/" style="font-size: 10px;">VGGNet</a> <a href="/tags/ZFNet/" style="font-size: 10px;">ZFNet</a> <a href="/tags/activation-algorithms/" style="font-size: 10px;">activation algorithms</a> <a href="/tags/gdb/" style="font-size: 10px;">gdb</a> <a href="/tags/network-structures/" style="font-size: 10px;">network structures</a> <a href="/tags/normalization-algorithms/" style="font-size: 10px;">normalization algorithms</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">Currently work for TCL Corporate Research Hong Kong Co., Ltd. Interested in high performance computing and machine learning.</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">yeephycho</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="http://yeephycho.github.io/blog_img/zombie2.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">yeephycho</h1>
			</hgroup>
			
			<p class="header-subtitle">Possibly, yeephycho is a phycho.</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/yeephycho.github.io">Home Page</a></li>
		        
					<li><a href="/archives">All article</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/yeephycho" title="github">github</a>
			        
						<a class="linkedin" target="_blank" href="https://www.linkedin.com/in/%E4%BB%A5%E7%92%87-%E8%83%A1-82ab00102" title="linkedin">linkedin</a>
			        
						<a class="facebook" target="_blank" href="https://www.facebook.com/profile.php?id=100004383827370" title="facebook">facebook</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-III" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/08/31/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-III/" class="article-date">
  	<time datetime="2016-08-31T11:36:10.000Z" itemprop="datePublished">2016-08-31</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      A Note to Techniques in Convolutional Neural Networks and Their Influences III (paper summary)
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Convolutional-Neural-Network/">Convolutional Neural Network</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Inception-v4/">Inception-v4</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MLPCONV/">MLPCONV</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VGGNet/">VGGNet</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ZFNet/">ZFNet</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Since we have already got some bases on how CNN works, so this post I prefer to focus more on the ideologies that make these architectures unique and the general technics that can improve the performance of the CNN. If you are new to this, please visit my previous <a href="http://yeephycho.github.io/2016/08/02/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-II/">post</a>, I believe it can help you to understand the paper or at least get the key point of the paper.</p>
<h2 id="ZFNet"><a href="#ZFNet" class="headerlink" title="ZFNet"></a><strong>ZFNet</strong></h2><p>Related paper is:<a href="https://arxiv.org/pdf/1311.2901v3.pdf" target="_blank" rel="external">Visualizing and Understanding Convolutional Networks</a>, published on Nov. 2013.<br><a id="more"></a></p>
<h3 id="Achievement"><a href="#Achievement" class="headerlink" title="Achievement"></a>Achievement</h3><p>ZFNet won the first place of ImageNet 2013 classification competition, the top-5 test error rate by combine multiple models (6 in total) is 14.8%.</p>
<h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><p>The architecture derives from AlexNet. The difference resides in (i) reduced the 1st layer filter size from 11x11 to 7x7 and (ii) made the stride of the convolution 2, rather than 4. Many later research and experiments show that by reducing the conv. stride and the conv. kernel size can avoid representation bottleneck, so the performance can be improved.</p>
<h3 id="Convnet-Visualization"><a href="#Convnet-Visualization" class="headerlink" title="Convnet Visualization"></a>Convnet Visualization</h3><p>This paper is famous for its visualization scheme! They raised a multi-layerd deconvolutional network (deconvnet) to visualize “the input stimuli that excite individual feature maps at any layer in the model” and it also “allows us to observe the evolution of features during training and to diagnose potential problems with the model”. </p>
<h4 id="Unpooling"><a href="#Unpooling" class="headerlink" title="Unpooling"></a>Unpooling</h4><p>Unpooling is a impossible operation, they used the way to approximate the feature map before the pooling operation in the forward network, the way is to record the position of each value of the pooled map in the unpooled feature maps, the rest position will be padded zero.</p>
<h4 id="Rectification"><a href="#Rectification" class="headerlink" title="Rectification"></a>Rectification</h4><p>After Unpooling, they add a rectification layer to guarantee the value is positive. My intuition is that this layer is invalid at the first reverse step, because the result must be always positive, but after the deconvolution operation, the value could be negative.</p>
<h4 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h4><p>This filtering cannot be more controversial. The name “deconvnet” is quite misleading. The way they do it to use the trained filter, do the vertical flip and horizontal flip to get a new filter. The new filter will serve as the filter to do the deconvolution. They didn’t explicitly address the padding scheme for the ReLUed feature maps at the inverse process.<br>The way I understand it is as follows:<br>Let’s say you have a 3x3 matrix and a 3x3 conv. kernel. If you want to recover the original matrix from conv. result. Maybe you should do the following:<div align="center"><br><img src="http://yeephycho.github.io/blog_img/deconv.JPG" alt="Deconvolution"><br></div><br>This is the most simple case, may be they just want to do this kind of thing to reveal how the network takes effect on the input image.<br>I cannot guarantee my understanding is correct here, if you have any other explanation, please let me know!</p>
<h2 id="Network-in-Network"><a href="#Network-in-Network" class="headerlink" title="Network in Network"></a><strong>Network in Network</strong></h2><p>Related paper is：<a href="https://arxiv.org/abs/1312.4400" target="_blank" rel="external">Network In Network</a>, published on Mar. 2014.</p>
<h3 id="Achievement-1"><a href="#Achievement-1" class="headerlink" title="Achievement"></a>Achievement</h3><p>Provide 8.81% error rate on cifar-10 dataset. Better than previous state-of-the-art.</p>
<h3 id="Mlpconv-layer"><a href="#Mlpconv-layer" class="headerlink" title="Mlpconv layer"></a>Mlpconv layer</h3><p>The concept of network in network or mlpconv layer inspires the Inception module. They replace the convolutional layer in CNN with a multi-layer perceptron, so the conv. op. can be more representative.<div align="center"><br><img src="http://yeephycho.github.io/blog_img/mlpconv.jpg" alt="MLPCONV"><br></div></p>
<h3 id="Global-Average-Pooling"><a href="#Global-Average-Pooling" class="headerlink" title="Global Average Pooling"></a>Global Average Pooling</h3><p>Global average pooling layer is usually the last layer of the network, it was raised to replace the fully connected layer. The idea is to use a feature map as the output of the network, each feature map represents a class, take the average of the value of the feature map to classify the image into different classes.<br>The author claims that GAP can be seen as a sort of regularizer to reduce the overfitting.</p>
<h3 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h3><p>The whole structure of the network is shown as follows:<div align="center"><br><img src="http://yeephycho.github.io/blog_img/nin.jpg" alt="Network In Network"><br></div></p>
<h2 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a><strong>VGGNet</strong></h2><p>Related paper is:<a href="https://arxiv.org/abs/1409.1556" target="_blank" rel="external">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>, published on Sep. 2014.</p>
<h2 id="Achievement-2"><a href="#Achievement-2" class="headerlink" title="Achievement"></a>Achievement</h2><p>VGGNet get the first place in ImageNet Challenge 2014 in localization and second place in classification tracks. VGGNet is one of the best architectures for deep learning beginners for its simplicity.<br>The later ResNet uses VGG-like structure as comparison to illustrate the effect of identity mapping operation. The author claims that the best single model prediction on ILSVRC test set top-5 error rate is 7.1%. </p>
<h2 id="Network-Architecture"><a href="#Network-Architecture" class="headerlink" title="Network Architecture"></a>Network Architecture</h2><p>The input of the network is 224x224 RGB image. For each input, subtract global mean from each pixel. Then, the image will pass through a stack of conv. layers. The conv. filter size is 3x3, which is the smallest size to capture the notion of left/right, up/down, center. Under certain scenario, 1x1 filters will be adopted, it can be seen as a linear transformation of the input channels. Conv. stride is fixed to 1 pixel. Spatial padding is 1 pixel for 3x3 conv. layers. Five max-pooling is adopted in the network, not every conv. layers are followed by max-pooling, the pooling is performed over a 2x2 pixel window, the pooling stride is 2.<br>Three fully-connected layers is used for classification, the first two have 4096 channels each, the third performs 1000 way ILSVRC classification and thus contains 1000 channels. Final layer is a soft-max layer. Activation function for the whole network is ReLU non-linearity. The whole structure of the network is shown as below:<div align="center"><br><img src="http://yeephycho.github.io/blog_img/VGG.JPG" alt="VGGNet Architecture"><br></div><br>In the above figure, <strong>conv3-64</strong> means the receptive field size is 3x3 and the output channel of the conv. op. is 64.</p>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>Training batch size is 256, momentum is 0.9, weight decay is 5x10^-4, dropout regularization for the first two fully-connected layers is set to 0.5, SGD learning rate was initially set to 10^-2, and decreased by a factor of 10 when the validation set accuracy stopped improving. The learning rate decreased 3 times in total. In the paper they mentioned about the pre-initialization of certain layers, so the training can converge with less epochs, and they also mentioned about the random initialization, that is initial the weights with zero mean and 10^-2 variance and zero biases.</p>
<h2 id="Comments"><a href="#Comments" class="headerlink" title="Comments"></a>Comments</h2><p>From my experience, VGGNet is a structure that is very suitable to verify your idea. It is relatively easy to generalize to different scenario. The drawback of this architecture is that its space complexity is too large. There are many structures that has a smaller size and better performance such as Inceptions.</p>
<h2 id="Inception-v4-Inception-ResNet"><a href="#Inception-v4-Inception-ResNet" class="headerlink" title="Inception-v4, Inception-ResNet"></a><strong>Inception-v4, Inception-ResNet</strong></h2><p>Related paper is: <a href="http://arxiv.org/pdf/1602.07261v2.pdf" target="_blank" rel="external">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a>, published on Aug. 2016 by Google.</p>
<h2 id="Achievement-3"><a href="#Achievement-3" class="headerlink" title="Achievement"></a>Achievement</h2><p>With an ensemble of three residual and one Inception-v4, achieve 3.08% top-5 error on the test set of the 2012 ImageNet classification challenge.</p>
<h2 id="Inception-v4"><a href="#Inception-v4" class="headerlink" title="Inception-v4"></a>Inception-v4</h2><p>Inception-v4 is a deeper and wider Inception network. Comparing to Inception-v3, it has more inception modules.<div align="center"><br><img src="http://yeephycho.github.io/blog_img/Inception_v4.jpg" alt="Inception-v4 architecture"><br></div><br>More clear image can be found <a href="http://yeephycho.github.io/blog_img/Inception_v4_hires.jpg">here</a>.</p>
<h2 id="Inception-ResNet"><a href="#Inception-ResNet" class="headerlink" title="Inception-ResNet"></a>Inception-ResNet</h2><p>Inception-ResNet is a hybrid of Inception net and Residual net. Currently, Inception-ResNet-2 is the state-of-the-art network structure on ImageNet dataset.<div align="center"><br><img src="http://yeephycho.github.io/blog_img/Inception_ResNet_v2.jpg" alt="Inception-ResNet-v2 architecture"><br></div><br>More clear image can be found <a href="http://yeephycho.github.io/blog_img/Inception_ResNet_v2_raw.jpg">here</a></p>
<h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>This paper is more like a report rather than a paper (the authors use report themselves). The general conclusion is that residual connection can speed up the training process but if you do not use residual connection, inception network can also get very good classification result.</p>
<p><br></p>
<h2 id="License"><a href="#License" class="headerlink" title="License"></a>License</h2><div align="center"><br>The content of this blog itself is licensed under the <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="external">Creative Commons Attribution 4.0 International License</a>.<br><img src="http://yeephycho.github.io/blog_img/license.jpg" alt="CC-BY-SA LICENCES"><br><br>The containing source code (if applicable) and the source code used to format and display that content is licensed under the <a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank" rel="external">Apache License 2.0</a>.<br><strong>Copyright [2016] [yeephycho]</strong><br>Licensed under the Apache License, Version 2.0 (the “License”);<br>you may not use this file except in compliance with the License.<br>You may obtain a copy of the License at<br><a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank" rel="external">Apache License 2.0</a><br>Unless required by applicable law or agreed to in writing, software<br>distributed under the License is distributed on an “AS IS” BASIS,<br>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either<br>express or implied. See the License for the specific language<br>governing permissions and limitations under the License.<br><img src="http://yeephycho.github.io/blog_img/APACHE.jpg" alt="APACHE LICENCES"><br></div>
      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/09/14/neural-style/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Neural Style -- A Computer Artist
        
      </div>
    </a>
  
  
    <a href="/2016/08/15/image-data-in-tensorflow/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Step by Step, A Tutorial on How to Feed Your Own Image Data to Tensorflow</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>








<section id="comments">
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'yeephycho'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>

</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2017 yeephycho
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: true
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>



<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-79750926-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
  <script id="dsq-count-scr" src="//yeephycho.disqus.com/count.js#disqus_thread" async></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>